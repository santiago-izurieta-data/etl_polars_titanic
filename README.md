# Titanic ETL Pipeline

![Python](https://img.shields.io/badge/python-v3.9+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ“‹ DescripciÃ³n

Pipeline ETL automatizado que procesa el dataset Titanic desde Kaggle, realiza transformaciones y agregaciones utilizando Polars, y genera visualizaciones finales para anÃ¡lisis de supervivencia. Todo el desarrollo se realizÃ³ en Google Colab.

## ğŸ¯ Objetivos

- Extraer datos desde CSV original del dataset Titanic.
- Limpiar y transformar datos inconsistentes (imputaciÃ³n de edades, categorizaciÃ³n de tarifas).
- Validar la calidad de los datos (duplicados, nulos y tipos de datos).
- Generar mÃ©tricas y agregaciones (tasas de supervivencia por clase y gÃ©nero).
- Visualizar resultados en grÃ¡ficos finales.

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Python 3.9+**
- **Polars** - ManipulaciÃ³n rÃ¡pida de datos
- **Pandas** - ConversiÃ³n opcional a DataFrame para visualizaciÃ³n
- **Matplotlib & Seaborn** - VisualizaciÃ³n
- **pytest** (opcional) - Testing de funciones ETL
- **logging** - Monitoreo y registro de procesos
- **Google Colab**

## ğŸ“ Estructura del Proyecto

etl_polars_titanic/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ bronze/ # Datos crudos
â”‚ â”œâ”€â”€ silver/ # Datos limpios
â”‚ â””â”€â”€ gold/ # Datos agregados
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ etl_polars_titanic_dataset.ipynb
â””â”€â”€ README.md

### ğŸ¥‰ Bronze
- ExtracciÃ³n desde fuente pÃºblica (Titanic CSV)
- Almacenamiento en Parquet sin transformaciones

### ğŸ¥ˆ Silver
- ImputaciÃ³n de edades nulas con la mediana
- CategorizaciÃ³n de tarifas (`Low`, `Medium`, `High`, `Very High`)
- Limpieza de duplicados
- TipificaciÃ³n correcta de columnas

### ğŸ¥‡ Gold
- Tasas de supervivencia por clase (`Pclass`)
- Tasas de supervivencia por gÃ©nero (`Sex`)
- Resultados en formato Parquet listos para anÃ¡lisis

## ğŸ“Š Visualizaciones
1. **Tasa de supervivencia por clase**
2. **Tasa de supervivencia por gÃ©nero**

Generadas automÃ¡ticamente al final del pipeline con Seaborn y Matplotlib.

## ğŸš€ InstalaciÃ³n

### Prerrequisitos

- Python 3.9 o superior
- pip
- Google Colab (recomendado para ejecuciÃ³n)

### Pasos

1. Clonar el repositorio:
    git clone https://github.com/tu-usuario/etl_polars_titanic.git
    cd etl_polars_titanic
2. Crear entorno virtual (opcional):
    python -m venv venv
    source venv/bin/activate  # En Windows: venv\Scripts\activate
3. Instalar dependencias:
    pip install -r requirements.txt

ğŸ’» Uso
En Colab

1. Abrir notebooks/etl_polars_titanic_dataset.ipynb.
2. Ejecutar todas las celdas para correr el pipeline completo.
3. Se generan automÃ¡ticamente:
    - Datos crudos en data/bronze/
    - Datos limpios en data/silver/
    - Datos agregados en data/gold/
    - Visualizaciones finales de tasas de supervivencia.

Desde script (opcional)
python src/pipeline.py

ğŸ§ª Testing

Aunque el proyecto aÃºn no incluye tests, se puede usar pytest para validar funciones ETL:
pytest tests/
Esto permite asegurar la calidad y consistencia de los datos si se agregan tests futuros.

ğŸ“Š Resultados

- Limpieza e imputaciÃ³n de datos de edades y tarifas.
- Tablas agregadas de supervivencia por clase y gÃ©nero.
- Visualizaciones finales de anÃ¡lisis de supervivencia.
- Pipeline reproducible en Google Colab.

ğŸ”„ Flujo del Pipeline

CSV Titanic â†’ Bronze â†’ Silver â†’ Gold â†’ Visualizaciones
â†“
Logging de procesos

ğŸ“ˆ PrÃ³ximas Mejoras

 Agregar tests unitarios con pytest
 Automatizar actualizaciones desde Kaggle
 DockerizaciÃ³n del proyecto
 Exportar resultados a Google Drive o GitHub automÃ¡ticamente
 IntegraciÃ³n con dashboard interactivo

ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - permite usar, modificar y distribuir el cÃ³digo con la obligaciÃ³n de mantener la licencia y crÃ©ditos al autor.

ğŸ‘¤ Autor

Santiago Izurieta

LinkedIn: https://ec.linkedin.com/in/santiago-izurieta-844324125

Portfolio: https://my-data-engineer-folio.lovable.app/

ğŸ™ Agradecimientos

Comunidad de Python y Polars
DocumentaciÃ³n de Kaggle y Seaborn
Google Colab para ejecuciÃ³n reproducible

